{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text\n",
        "!pip install tensorflow-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aHTjKvPgBo4t",
        "outputId": "ea7594e4-c254-4bdd-fc68-f15429128a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (2.18.1)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text) (0.1.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (4.9.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.9)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.26.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.25.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.16.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (1.17.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (1.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2025.1.31)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-datasets) (25.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.67.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.6.0\n",
        "!pip install tensorflow_datasets==4.4.0\n",
        "!pip install nltk==3.6\n",
        "!pip install pandas==1.3.3\n"
      ],
      "metadata": {
        "id": "lWIfSCMquneT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.3"
      ],
      "metadata": {
        "id": "z2bAUyIwvbSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb_5bl7G_n30"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import nltk\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "#for the miniBert\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tfds.__version__)\n",
        "print(nltk.__version__)\n",
        "print(pd.__version__)\n"
      ],
      "metadata": {
        "id": "bcGvDRpwudan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGyTAx-pAn1f"
      },
      "source": [
        "## Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S17Nfn6W_vhd"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"training_dataset.csv\", encoding = 'utf-8')\n",
        "data = data.drop('conv_id', axis = 1)\n",
        "data = data.drop('utterance_idx', axis = 1)\n",
        "data = data.drop('speaker_idx', axis = 1)\n",
        "data = data.drop('selfeval', axis = 1)\n",
        "data = data.drop('tags', axis = 1)\n",
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hpFEBCIAn1h"
      },
      "source": [
        "## Grouping Emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xe-6DAnAn1i"
      },
      "outputs": [],
      "source": [
        "emotions = {}\n",
        "emotions['excited'] = emotions['surprised'] = emotions['joyful'] = \"excited\"\n",
        "emotions['afraid'] = emotions['terrified'] = emotions['anxious']= emotions['apprehensive']='afraid'\n",
        "emotions['disgusted'] = emotions['embarrassed']= emotions['guilty'] = emotions['ashamed'] =\"disgusted\"\n",
        "emotions['angry'] = emotions ['annoyed'] = emotions['jealous'] =emotions[ 'furious' ] = \"annoyed\"\n",
        "emotions['faithful'] = emotions ['trusting']=emotions ['grateful']= emotions['caring'] = emotions['hopeful'] = \"grateful\"\n",
        "emotions['sad'] = emotions['disappointed'] = emotions['devastated']= emotions ['lonely']=emotions['nostalgic']=emotions['sentimental'] = \"disappointed\"\n",
        "emotions['proud']= emotions['impressed']= emotions['content'] = \"impressed\"\n",
        "emotions['anticipating']=emotions[ 'prepared']=emotions ['confident'] = \"prepared\"\n",
        "dicttt=emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B147qKb_0ks"
      },
      "outputs": [],
      "source": [
        "context = data['context']\n",
        "question = data['prompt']\n",
        "answer = data['utterance']\n",
        "\n",
        "print(len(context))\n",
        "print(len(question))\n",
        "print(len(answer))\n",
        "\n",
        "\n",
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 50000\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    # Make sure sentence is a string\n",
        "    if not isinstance(sentence, str):\n",
        "        sentence = str(sentence)  # Convert to string if it's not already\n",
        "\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "context = [preprocess_sentence(emotions[sentence]) for sentence in context]\n",
        "questions = [preprocess_sentence(sentence) for sentence in question]\n",
        "answers = [preprocess_sentence(sentence) for sentence in answer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfOOK5f7Wm6c"
      },
      "outputs": [],
      "source": [
        "print('Sample question: {}'.format(questions[20]))\n",
        "print('Sample answer: {}'.format(answers[20]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "-bRQb26DemAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build tokenizer using tfds for both questions and answers\n",
        "#tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "#questions + answers + context , target_vocab_size=2**13)\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus( questions + answers + context, target_vocab_size=2**13)\n",
        "\n",
        "#Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "#Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n"
      ],
      "metadata": {
        "id": "TjB20khfw_3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5h8pvRUTFt5"
      },
      "outputs": [],
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YESTPgeg_XgT"
      },
      "outputs": [],
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "\n",
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs, context):\n",
        "  tokenized_inputs, tokenized_outputs, tokenized_context = [], [], []\n",
        "\n",
        "  for (sentence1, sentence2, emotion) in zip(inputs, outputs, context):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    emotion = tokenizer.encode(emotion)\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "      tokenized_context.append(emotion)\n",
        "\n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_context = tf.keras.preprocessing.sequence.pad_sequences( # New line\n",
        "      tokenized_context, maxlen=MAX_LENGTH, padding='post') # Pad context\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs, tokenized_context\n",
        "\n",
        "\n",
        "questions, answers, context = tokenize_and_filter(questions, answers, context)\n",
        "\n",
        "print(questions[:10], answers[:10], context[:10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"Hello, how are you?\"\n",
        "tokenized_text = tokenizer.encode(sample_text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "MuETrnh-LQm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pohHm8IRWlIH"
      },
      "outputs": [],
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bert"
      ],
      "metadata": {
        "id": "FtXHDLwsZAlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hwsCbmM9Y99c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bert with swish"
      ],
      "metadata": {
        "id": "2vVFUp5TcZn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "config.hidden_act = 'swish'  # Change the activation function to 'swish'\n",
        "\n",
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel(config)  #Create the model"
      ],
      "metadata": {
        "id": "PyX_BT-gcchx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini Bert"
      ],
      "metadata": {
        "id": "Eia9ozz_WjnB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mini Bert\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "mini_bert_tokenizer = AutoTokenizer.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")\n",
        "mini_bert_model = AutoModel.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")\n"
      ],
      "metadata": {
        "id": "LuOnQG4cWnR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini Bert using swish"
      ],
      "metadata": {
        "id": "_XpumZYdexhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig.from_pretrained(\"google/bert_uncased_L-4_H-512_A-8\")\n",
        "config.hidden_act = 'swish'  # Change the activation function to 'swish'\n",
        "\n",
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel(config)  # Create the model"
      ],
      "metadata": {
        "id": "tM_B3FV6e0J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S50jT4upWh5c"
      },
      "source": [
        "### Create `tf.data.Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pttC3XxgAXWQ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "answers = np.array(answers)\n",
        "answers = answers.reshape(-1, 1)\n",
        "\n",
        "\n",
        "questions = tf.convert_to_tensor(questions, dtype=tf.float32)\n",
        "context = tf.convert_to_tensor(context, dtype=tf.float32)\n",
        "answers = tf.convert_to_tensor(answers, dtype=tf.int32)  # Changed dtype to tf.int32min_len = min(len(questions), len(answers), len(context))\n",
        "questions = questions[:min_len]\n",
        "answers = answers[:min_len]\n",
        "context = context[:min_len]\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'input1': questions,\n",
        "        'input2': context,\n",
        "        'dec_inputs': answers[:, :-1] if answers.shape[1] > 1 else answers\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:] if answers.shape[1] > 1 else answers[:, 0]\n",
        "    },\n",
        "))\n",
        "\n",
        "# **Key Change:** Cast the 'outputs' to tf.int32 before batching\n",
        "dataset = dataset.map(lambda inputs, outputs: (inputs, {'outputs': tf.cast(outputs['outputs'], tf.int32)}))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3IYzP9CAn1m"
      },
      "outputs": [],
      "source": [
        "len(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mU8yNWpwPlS7"
      },
      "outputs": [],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9eeMPjGXmI1"
      },
      "source": [
        "## Attention\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENfqAFna_50H"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "    \"\"\"Calculate the attention weights.\"\"\"\n",
        "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    # Ensure depth is cast to float32 to avoid dtype mismatches\n",
        "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "    logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "    # Add the mask to zero out padding tokens\n",
        "    if mask is not None:\n",
        "        logits += (mask * tf.cast(-1e9, logits.dtype))  # Ensure dtype consistency\n",
        "\n",
        "    # Softmax is normalized on the last axis (seq_len_k)\n",
        "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, value)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "GXRe6_h8iOgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwmOB9HvVbyh"
      },
      "source": [
        "### Multi-head attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9eYssGIAG4h"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDUX7Oa8Xudj"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5QlgXsxYirg"
      },
      "source": [
        "### Masking\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imCQ0jrvWhC7"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "    \"\"\"\n",
        "    Creates a padding mask for a given tensor `x`.\n",
        "\n",
        "    Args:\n",
        "        x: A tensor representing input sequences.\n",
        "\n",
        "    Returns:\n",
        "        A padding mask with shape (batch_size, 1, 1, seq_len).\n",
        "    \"\"\"\n",
        "    mask = tf.cast(tf.math.equal(x, 0), dtype=tf.float32)\n",
        "    return tf.expand_dims(tf.expand_dims(mask, axis=1), axis=1)  # (batch_size, 1, 1, seq_len)\n"
      ],
      "metadata": {
        "id": "bGzSDc-IpjKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrwtsqrfWd-3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJAicy1zW1QT"
      },
      "source": [
        "Look-ahead mask to mask the future tokens in a sequence.\n",
        "We also mask out pad tokens.\n",
        "\n",
        "i.e. To predict the third word, only the first and second word will be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSVdD2zKWaXx"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "    \"\"\"\n",
        "    Creates a look-ahead mask for masking future tokens in a sequence.\n",
        "    This mask prevents the model from attending to tokens that come after the current position.\n",
        "\n",
        "    Args:\n",
        "        x: The input sequence with shape (batch_size, seq_len).\n",
        "\n",
        "    Returns:\n",
        "        A Tensor with shape (batch_size, 1, seq_len, seq_len).\n",
        "    \"\"\"\n",
        "    seq_len = tf.shape(x)[1]  # Get the sequence length from the second dimension\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len), dtype=tf.float32), -1, 0)\n",
        "    look_ahead_mask = tf.expand_dims(look_ahead_mask, axis=0)  # Add batch dimension\n",
        "    look_ahead_mask = tf.expand_dims(look_ahead_mask, axis=0)  # Add head dimension\n",
        "\n",
        "    # Create padding mask\n",
        "    padding_mask = create_padding_mask(x)  # Already returns shape (batch_size, 1, 1, seq_len)\n",
        "\n",
        "    # Combine look_ahead_mask and padding_mask\n",
        "    final_mask = tf.maximum(look_ahead_mask, tf.cast(padding_mask, dtype=tf.float32))  # Ensure dtype consistency\n",
        "\n",
        "    return final_mask\n"
      ],
      "metadata": {
        "id": "UhhVqqH2pfpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhwz9xzxWcod"
      },
      "outputs": [],
      "source": [
        "print(create_look_ahead_mask(tf.constant([[2, 8, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpR7kz4jFkPJ"
      },
      "source": [
        "### Positional encoding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Oibz2es-qW"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  # def call(self, inputs):\n",
        "  #   return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "  def call(self, inputs):\n",
        "      # Convert SparseTensor to dense if necessary\n",
        "      if isinstance(inputs, tf.SparseTensor):\n",
        "          inputs = tf.sparse.to_dense(inputs)\n",
        "\n",
        "      return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UC_fQehi3_Yh"
      },
      "outputs": [],
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVazCemoW2Ye"
      },
      "source": [
        "### Encoder Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5guJOLJmfcuX"
      },
      "outputs": [],
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K16BIGSKfkve"
      },
      "outputs": [],
      "source": [
        "sample_encoder_layer = encoder_layer(\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_encoder_layer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_encoder_layer, to_file='encoder_layer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r8lWGClfi_1"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRfugon5Wy-Y"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "\n",
        "    input1 = tf.keras.Input(shape=(None,), name=\"input1\")\n",
        "    input2 = tf.keras.Input(shape=(None,), name=\"input2\")  # Assuming input2 is needed\n",
        "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "    # Embedding layers for input1 and input2\n",
        "    embedding1 = tf.keras.layers.Embedding(vocab_size, d_model)(input1)\n",
        "    embedding1 *= tf.math.sqrt(tf.cast(d_model, tf.float32))  # Scale embeddings\n",
        "\n",
        "    embedding2 = tf.keras.layers.Embedding(vocab_size, d_model)(input2)\n",
        "    embedding2 *= tf.math.sqrt(tf.cast(d_model, tf.float32))  # Scale embeddings\n",
        "\n",
        "    # Combine the embeddings (assuming both inputs are needed)\n",
        "    embeddings = embedding1 + embedding2\n",
        "    embeddings = tf.keras.layers.LayerNormalization(epsilon=1e-6)(embeddings)\n",
        "\n",
        "    # Positional Encoding\n",
        "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "    # Dropout\n",
        "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "    # Multiple encoder layers\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_layer(\n",
        "            units=units,\n",
        "            d_model=d_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            name=f\"encoder_layer_{i}\",\n",
        "        )([outputs, padding_mask])\n",
        "\n",
        "    # Return the model\n",
        "    return tf.keras.Model(\n",
        "        inputs=[input1, input2, padding_mask], outputs=outputs, name=name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNxCnjrvglnx"
      },
      "outputs": [],
      "source": [
        "sample_encoder = encoder(\n",
        "    vocab_size=8192,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_encoder\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "   sample_encoder, to_file='encoder.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af66azvgW9P-"
      },
      "source": [
        "### Decoder Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mLvvNMWgDnf"
      },
      "outputs": [],
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8M1NrQ_NgEaM"
      },
      "outputs": [],
      "source": [
        "sample_decoder_layer = decoder_layer(\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_decoder_layer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_decoder_layer, to_file='decoder_layer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPSKnjS-gE_q"
      },
      "source": [
        "### Decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYRx7YzCW4bu"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  # embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "  embeddings = tf.sparse.to_dense(embeddings) if isinstance(embeddings, tf.SparseTensor) else embeddings\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUdK8jb9hlTZ"
      },
      "outputs": [],
      "source": [
        "sample_decoder = decoder(\n",
        "    vocab_size=8192,\n",
        "    num_layers=2,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_decoder\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_decoder, to_file='decoder.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl0o97RJXAqw"
      },
      "source": [
        "### Transformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW-v7Fz6XAfC"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  input1 = tf.keras.Input(shape=(None,), name=\"input1\")\n",
        "  input2 = tf.keras.Input(shape=(None,), name=\"input2\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(input1)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(input1)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[input1, input2, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[input1, input2, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tranformer using 'swish'"
      ],
      "metadata": {
        "id": "JzpfXvQ7dTiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        assert d_model % num_heads == 0\n",
        "        self.depth = d_model // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(d_model,activation = 'swish')\n",
        "        self.key_dense = tf.keras.layers.Dense(d_model,activation = 'swish')\n",
        "        self.value_dense = tf.keras.layers.Dense(d_model,activation = 'swish')\n",
        "        self.final_dense = tf.keras.layers.Dense(d_model,activation = 'swish')\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "      # Splits the input tensor into num_heads for multi-head attention.\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "\n",
        "    def scaled_dot_product_attention(self, query, key, value, mask):\n",
        "      # Computes attention scores based on the query and key vectors.\n",
        "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        logits = matmul_qk / tf.math.sqrt(depth)\n",
        "        if mask is not None:\n",
        "            logits += (mask * -1e9)\n",
        "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "        return tf.matmul(attention_weights, value), attention_weights\n",
        "\n",
        "    def call(self, query, key, value, mask):\n",
        "      # Forward Pass\n",
        "      # Combines all steps to compute multi-head attention.\n",
        "        batch_size = tf.shape(query)[0]\n",
        "        query = self.split_heads(self.query_dense(query), batch_size)\n",
        "        key = self.split_heads(self.key_dense(key), batch_size)\n",
        "        value = self.split_heads(self.value_dense(value), batch_size)\n",
        "        attention, weights = self.scaled_dot_product_attention(query, key, value, mask)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.d_model))\n",
        "        return self.final_dense(concat_attention), weights\n"
      ],
      "metadata": {
        "id": "ft3NkdsZdT77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aihJLVq_iJ_T"
      },
      "outputs": [],
      "source": [
        "sample_transformer = transformer(\n",
        "    vocab_size=8192,\n",
        "    num_layers=4,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_transformer\")\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    sample_transformer, to_file='transformer.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HD7GK-nh_KT"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDDxNpA-5Q5t"
      },
      "source": [
        "### Initialize model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE3unrOT5M5z"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic learning rate:\n",
        "\n",
        "Dynamically adjusts the learning rate during training to help the model converge efficiently.\n",
        "\n",
        "* initial_learning_rate=1e-3: The starting learning rate.\n",
        "* decay_steps=10000: Number of steps after which the learning rate is decayed.\n",
        "* decay_rate=0.96: The factor by which the learning rate is multiplied after every decay step"
      ],
      "metadata": {
        "id": "Epg-LM1BQFy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_learning_rate=0.05\n",
        "decay_steps=10000\n",
        "decay_rate=0.96\n",
        "\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps, decay_rate)\n",
        "#learning_rate = 0.005"
      ],
      "metadata": {
        "id": "j6GTM2n5QHSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss Rate Tracking"
      ],
      "metadata": {
        "id": "crtm338LQS0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LossTracker(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.losses_per_batch = []\n",
        "        self.losses_per_epoch = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        # Record the loss at the end of each batch\n",
        "        self.losses_per_batch.append(logs.get(\"loss\"))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Record the average loss at the end of each epoch\n",
        "        self.losses_per_epoch.append(logs.get(\"loss\"))\n",
        "\n",
        "    def plot_losses(self):\n",
        "        # Plot Loss per Batch\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(self.losses_per_batch, label=\"Loss per Batch\")\n",
        "        plt.title(\"Loss per Batch\")\n",
        "        plt.xlabel(\"Batch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot Loss per Epoch\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(self.losses_per_epoch, label=\"Loss per Epoch\", marker=\"o\")\n",
        "        plt.title(\"Loss per Epoch\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "QTHZf59fQPXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Tracker"
      ],
      "metadata": {
        "id": "PRI13kjhQZ85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AccuracyTracker(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.accuracy_per_batch = []\n",
        "        self.accuracy_per_epoch = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        # Use \"outputs_accuracy\" instead of \"accuracy\"\n",
        "        accuracy = logs.get(\"outputs_accuracy\")\n",
        "      #  print(f\"Batch {batch + 1}: outputs_accuracy = {accuracy}\")  # Debug log\n",
        "        self.accuracy_per_batch.append(accuracy)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Use \"outputs_accuracy\" instead of \"accuracy\"\n",
        "        accuracy = logs.get(\"outputs_accuracy\")\n",
        "        print(f\"Epoch {epoch + 1}: outputs_accuracy = {accuracy}\")  # Debug log\n",
        "        self.accuracy_per_epoch.append(accuracy)\n",
        "\n",
        "    def plot_accuracy(self):\n",
        "        # Plot Accuracy per Batch\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(self.accuracy_per_batch, label=\"Accuracy per Batch\")\n",
        "        plt.title(\"Accuracy per Batch\")\n",
        "        plt.xlabel(\"Batch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot Accuracy per Epoch\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(self.accuracy_per_epoch, label=\"Accuracy per Epoch\", marker=\"o\")\n",
        "        plt.title(\"Accuracy per Epoch\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "887fHKpJQZDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_GCb0LaV1tI"
      },
      "source": [
        "### Loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UInVM9iGAMv1"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  # print(f\"y_true: {y_true.shape}\")\n",
        "  # print(f\"y_pred: {y_pred.shape}\")\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dynamic loss function"
      ],
      "metadata": {
        "id": "caTSFdUGQhfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the dynamic loss scaler class\n",
        "class DynamicLossScaler:\n",
        "    def __init__(self, initial_weight=1.0, decay_rate=0.9):\n",
        "        self.initial_weight = initial_weight\n",
        "        self.decay_rate = decay_rate\n",
        "\n",
        "    def get_scaling_factor(self, epoch):\n",
        "        # Calculate the scaling factor dynamically based on the current epoch\n",
        "        return self.initial_weight * (self.decay_rate ** epoch)\n",
        "\n",
        "# Instantiate the dynamic scaler\n",
        "initial_weight = 0.7\n",
        "decay_rate = 0.95\n",
        "dynamic_loss_scaler = DynamicLossScaler(initial_weight, decay_rate)\n",
        "\n",
        "# Precompute the number of batches in the dataset\n",
        "batches_per_epoch = tf.data.experimental.cardinality(dataset).numpy()\n",
        "\n",
        "# Define the dynamic loss function\n",
        "def dynamic_loss_function(y_true, y_pred, epoch):\n",
        "    scaling_factor = dynamic_loss_scaler.get_scaling_factor(epoch)\n",
        "    mask = tf.cast(tf.math.not_equal(y_true, 0), tf.float32)\n",
        "    loss = loss_object(y_true, y_pred) * mask\n",
        "    scaled_loss = scaling_factor * (tf.reduce_sum(loss) / tf.reduce_sum(mask))\n",
        "    return scaled_loss\n",
        "\n",
        "# Define the wrapper for dynamic loss to use in training\n",
        "def loss_function_with_dynamic_scaling(y_true, y_pred):\n",
        "    # Calculate the current epoch dynamically\n",
        "    epoch = tf.keras.backend.get_value(model.optimizer.iterations) // batches_per_epoch\n",
        "    return dynamic_loss_function(y_true, y_pred, epoch)\n",
        "\n",
        "# Define a callback to log the scaling factor during training\n",
        "class DynamicLossUpdater(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, scaler, initial_epoch=0):\n",
        "        super().__init__()\n",
        "        self.scaler = scaler\n",
        "        self.epoch = initial_epoch\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch = epoch  # Update the epoch\n",
        "        scaling_factor = self.scaler.get_scaling_factor(self.epoch)\n",
        "     #   print(f\"Epoch {self.epoch + 1}: Scaling Factor = {scaling_factor}\")\n",
        "\n",
        "# Define the dynamic loss updater callback\n",
        "dynamic_loss_updater = DynamicLossUpdater(dynamic_loss_scaler)\n"
      ],
      "metadata": {
        "id": "0DGFh2Joi07k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### validation loss based adjustment"
      ],
      "metadata": {
        "id": "vovsLqLEQo8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidationLossDynamicDropout(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, initial_dropout, final_dropout, patience=5, factor=0.1):\n",
        "        super().__init__()\n",
        "        self.initial_dropout = initial_dropout\n",
        "        self.final_dropout = final_dropout\n",
        "        self.patience = patience\n",
        "        self.factor = factor\n",
        "        self.best_val_loss = np.inf\n",
        "        self.wait = 0\n",
        "        self.scaled_dropouts = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        if val_loss is not None:\n",
        "            if val_loss < self.best_val_loss:\n",
        "                self.best_val_loss = val_loss\n",
        "                self.wait = 0\n",
        "            else:\n",
        "                self.wait += 1\n",
        "\n",
        "            if self.wait >= self.patience:\n",
        "                # Reduce dropout if validation loss has not improved\n",
        "                for layer in self.model.layers:\n",
        "                    if hasattr(layer, \"rate\"):  # Check if the layer is a Dropout layer\n",
        "                        new_dropout = max(self.final_dropout, layer.rate * (1 - self.factor))\n",
        "                        layer.rate = new_dropout\n",
        "                        self.scaled_dropouts.append(new_dropout)\n",
        "                print(f\"Epoch {epoch + 1}: Reduced Dropout Rate to {new_dropout:.4f}\")\n",
        "                self.wait = 0\n",
        "\n",
        "    def plot_scaled_dropouts(self):\n",
        "        \"\"\"Plot the dropout rates over epochs.\"\"\"\n",
        "        plt.plot(range(1, len(self.scaled_dropouts) + 1), self.scaled_dropouts, label=\"Validation Loss-Based\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Dropout Rate\")\n",
        "        plt.title(\"Dropout Rate Adjustments Based on Validation Loss\")\n",
        "        plt.legend()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "3OaOQxqLQppZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dynamic Dropout"
      ],
      "metadata": {
        "id": "5dm6v8EhQyeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class DynamicDropoutUpdater(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, strategy, initial_dropout, final_dropout, total_epochs):\n",
        "        super().__init__()\n",
        "        self.strategy = strategy\n",
        "        self.initial_dropout = initial_dropout\n",
        "        self.final_dropout = final_dropout\n",
        "        self.total_epochs = total_epochs\n",
        "        self.scaled_dropouts = []\n",
        "\n",
        "    def calculate_dropout(self, epoch):\n",
        "        \"\"\"Calculate the dropout rate dynamically based on the chosen strategy.\"\"\"\n",
        "        if self.strategy == \"linear\":\n",
        "            return self.initial_dropout + (self.final_dropout - self.initial_dropout) * (epoch / self.total_epochs)\n",
        "        elif self.strategy == \"exponential\":\n",
        "            # Ensure dropout remains between initial and final values\n",
        "            alpha = np.log(self.final_dropout / self.initial_dropout) / self.total_epochs\n",
        "            dropout = self.initial_dropout * np.exp(alpha * epoch)\n",
        "            return np.clip(dropout, self.final_dropout, self.initial_dropout)\n",
        "        elif self.strategy == \"sinusoidal\":\n",
        "            # Ensure sinusoidal values stay within range\n",
        "            midpoint = (self.initial_dropout + self.final_dropout) / 2\n",
        "            amplitude = (self.initial_dropout - self.final_dropout) / 2\n",
        "            return midpoint + amplitude * np.sin(2 * np.pi * epoch / self.total_epochs)\n",
        "        elif self.strategy == \"cosine\":\n",
        "            # Ensure cosine values stay within range\n",
        "            return self.final_dropout + (self.initial_dropout - self.final_dropout) * (\n",
        "                0.5 * (1 + np.cos(np.pi * epoch / self.total_epochs))\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported strategy: {self.strategy}\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        \"\"\"Adjust the dropout rate dynamically at the beginning of each epoch.\"\"\"\n",
        "        new_dropout = self.calculate_dropout(epoch)\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, \"rate\"):  # If the layer has a `rate` attribute (Dropout layers)\n",
        "                layer.rate = new_dropout\n",
        "        self.scaled_dropouts.append(new_dropout)\n",
        "        print(f\"Epoch {epoch + 1}: Dropout Rate = {new_dropout:.4f}\")\n",
        "\n",
        "    def plot_scaled_dropouts(self):\n",
        "        \"\"\"Plot the dropout rates over epochs.\"\"\"\n",
        "        plt.plot(range(1, len(self.scaled_dropouts) + 1), self.scaled_dropouts, label=f\"Strategy: {self.strategy}\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Dropout Rate\")\n",
        "        plt.title(\"Dynamic Dropout Scaling over Epochs\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Choose strategy: 'linear', 'exponential', 'sinusoidal', or 'cosine'\n",
        "strategy = \"cosine\"\n",
        "\n",
        "# Create a DynamicDropoutUpdater callback\n",
        "dynamic_dropout_updater = DynamicDropoutUpdater(\n",
        "    strategy=strategy,\n",
        "    initial_dropout=0.3,  # Start with 30% dropout\n",
        "    final_dropout=0.1,    # Reduce to 10% dropout\n",
        "    total_epochs=EPOCHS\n",
        ")\n"
      ],
      "metadata": {
        "id": "L4_OiXNYQzO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvFM9ajSVybP"
      },
      "source": [
        "### Custom learning rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW3SeLDhAMJd"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67BoG_UeaHHw"
      },
      "outputs": [],
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCqve3kwWCxd"
      },
      "source": [
        "### Compile Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QqojIa5WEQq"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# Initialize the trackers\n",
        "loss_tracker = LossTracker()\n",
        "accuracy_tracker = AccuracyTracker()\n",
        "\n",
        "#model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "# Compile the model with metrics for the primary output\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_function_with_dynamic_scaling, # loss = loss_funcrion\n",
        "    metrics={\"outputs\": [\"accuracy\"]}  # Metrics for the 'outputs' key only\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDMd69urLNuc"
      },
      "source": [
        "### Fit model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7iahRzlLNG2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS, callbacks=[loss_tracker, accuracy_tracker,dynamic_loss_updater,dynamic_dropout_updater])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIP_P2B58n_h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "name": "DeepLearningProject.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}